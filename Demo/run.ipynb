{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ddcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "\n",
    "!uv pip install pandas\n",
    "from inference import StyleTTS2\n",
    "\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import torch.cuda\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9cecbe",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"Configs/config.yaml\"\n",
    "models_path = \"Models/Finetune/base_model.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803110e",
   "metadata": {},
   "source": [
    "### Synthesize speech\n",
    "\n",
    "Little Note:\n",
    "\n",
    "- You don't need to add language tokens everywhere, espeak can detect and handle them automatically most of the time.\n",
    "\n",
    "- Reference audio has a huge impact on the result. It is best to select audio around 10s long and consistent in both tone and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78396f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = {\n",
    "    \"id_1\": {\n",
    "        \"path\": \"./Demo/reference_audio/vn_1.wav\",  #Ref audio path\n",
    "        \"lang\": \"en-us\",                            #Default language\n",
    "        \"speed\": 1.0,                               #Speaking speed\n",
    "    },\n",
    "    \"id_2\": {\n",
    "        \"path\": \"./Demo/reference_audio/vn_2.wav\",\n",
    "        \"lang\": \"en-us\",\n",
    "        \"speed\": 1.0,\n",
    "    },\n",
    "}\n",
    "for id in speakers:\n",
    "    max_samples = 24000*20 #max 20 seconds ref audio\n",
    "    print(speakers[id]['path'])\n",
    "    wave, sr = librosa.load(speakers[id]['path'], sr=24000)\n",
    "    audio, index = librosa.effects.trim(wave, top_db=30)\n",
    "    if sr != 24000:              audio = librosa.resample(audio, sr, 24000)\n",
    "    if len(audio) > max_samples: audio = audio[:max_samples]\n",
    "    display(ipd.Audio(audio, rate=24000, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395959f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Next to the Bach Dang Port is the Nguyen Hue Avenue, as seen in a photo dated in the 1970s and as seen today. One side of the road leads to the Saigon River, while the other side leads to the Ho Chi Minh City People’s Committee, built from 1898 to 1909. The road spans 700 meters from the People’s Committee headquarters to the Bach Dang Port. In the past, it was the Kinh Lon Channel that brings water from the Saigon River to Gia Dinh. In 1887, the French covered up the channel to build a road, calling it the Chamer Avenue. By 1956, the then-government of the Republic of Vietnam changed the avenue’s name to Nguyen Hue. In 2004, Ho Chi Minh City restored the flower street on the avenue, and renovated it into a walking street as it is today in 2014.\n",
    "'''\n",
    "\n",
    "# Use phonemes directly\n",
    "text = \"ʃalˈom olˈam! mˈa korˈe? bˈo teʁˈed, toχˈal ktsˈat tˈeʁed. ʔˈejze tχinˈa! jihjˈe tχˈina tovˈa! bˈo niʃtˈe bˈiʁa beʔˈiʁ habiʁˈa! hˈu pitˈa ʔotˈi leʔeχˈol pˈita ʃawˈaʁma!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16194211",
   "metadata": {},
   "outputs": [],
   "source": [
    "model             = StyleTTS2(config_path, models_path).eval().to(device)\n",
    "default_speaker   = \"[id_1]\"  #STR    Default speaker used when no speaker_id is provided in the input\n",
    "avg_style         = True     #BOOL   Split the ref audio and calculate the avg styles.\n",
    "stabilize         = True      #BOOL   Stabilize speaking speed.\n",
    "denoise           = 0.6       #FLOAT  Adjust the strength of the denoiser. Value range is [0, 1]\n",
    "n_merge           = 18        #INT    Avoid short sentences by merging when a sentence has fewer than n words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc138e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    styles = model.get_styles(speakers, denoise, avg_style)\n",
    "    r = model.generate(text, styles, stabilize, n_merge, \"[id_1]\", is_phonemes = True) # default speaker\n",
    "\n",
    "print('Synthesized:')\n",
    "display(ipd.Audio(r, rate=24000, normalize=True))\n",
    "\n",
    "import scipy.io.wavfile as wavfile\n",
    "wavfile.write(\"audio.wav\", 24000, (r * 32767).astype(\"int16\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
